{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script provides a framework for loading the data, creating new features from it and generating the predictions file. You can use it to play around with different feature combinations and classifiers to see what works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import preprocessing, metrics, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('input_data/weather_clean.csv')\n",
    "train = pd.read_csv('input_data/train.csv')\n",
    "test = pd.read_csv('input_data/test.csv')\n",
    "sample = pd.read_csv('input_data/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = weather.drop(['Depart', 'DewPoint', 'WetBulb', 'CodeSum', 'Heat', 'Cool',\n",
    "                        'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed', 'Sunrise', 'Sunset'], axis=1)\n",
    "train = train.drop(['NumMosquitos', 'Address', 'Block', 'Street', 'AddressNumberAndStreet', 'AddressAccuracy', 'Trap'], axis=1)\n",
    "test = test.drop(['Id', 'Address', 'Block', 'Street', 'AddressNumberAndStreet', 'AddressAccuracy', 'Trap'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Date strings to DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['Date'] = weather['Date'].apply(pd.to_datetime)\n",
    "# spray['Date'] = spray['Date'].apply(pd.to_datetime)\n",
    "train['Date'] = train['Date'].apply(pd.to_datetime)\n",
    "test['Date'] = test['Date'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather-related features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature: accumulated degree weeks with base temperature = 72 F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data for each station\n",
    "weather_st1 = weather[weather['Station'] == 1]\n",
    "weather_st2 = weather[weather['Station'] == 2]\n",
    "\n",
    "# Restore indexing\n",
    "weather_st1 = weather_st1.reset_index(drop=True)\n",
    "weather_st2 = weather_st2.reset_index(drop=True)\n",
    "\n",
    "# Remove the station row\n",
    "weather_st1 = weather_st1.drop('Station', axis=1)\n",
    "weather_st2 = weather_st2.drop('Station', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_st1['Heat'] = 0\n",
    "weather_st2['Heat'] = 0\n",
    "weather_st1['CumulativeHeat'] = 0\n",
    "weather_st2['CumulativeHeat'] = 0\n",
    "\n",
    "t_base = 72 #degrees Fahrenheit\n",
    "weather_st1['Heat'] = weather_st1['Tavg'] - t_base\n",
    "weather_st2['Heat'] = weather_st2['Tavg'] - t_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accumulate degree days for st1 & st2\n",
    "for index, row in weather_st1.iterrows():\n",
    "    year = row['Date'].year\n",
    "    first_row_of_year = weather_st1['Date'][weather_st1['Date'] == pd.datetime(year, 5, 1)].index[0]\n",
    "    weather_st1.loc[index, 'CumulativeHeat'] = weather_st1['Heat'][first_row_of_year:index].sum()\n",
    "\n",
    "for index, row in weather_st2.iterrows():\n",
    "    year = row['Date'].year\n",
    "    first_row_of_year = weather_st2['Date'][weather_st2['Date'] == pd.datetime(year, 5, 1)].index[0]\n",
    "    weather_st2.loc[index, 'CumulativeHeat'] = weather_st2['Heat'][first_row_of_year:index].sum()\n",
    "\n",
    "\n",
    "# Transform into degree weeks\n",
    "weather_st1['CumulativeHeat'] /= 7\n",
    "weather_st2['CumulativeHeat'] /= 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##New Feature: total degree days over last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_st1['HeatWeek'] = 0\n",
    "weather_st2['HeatWeek'] = 0\n",
    "\n",
    "N_days = 7\n",
    "\n",
    "for index, row in weather_st1.iterrows():\n",
    "    weather_st1.loc[index, 'HeatWeek'] = weather_st1['Heat'][max(index-N_days, 0):index].sum()\n",
    "\n",
    "for index, row in weather_st2.iterrows():\n",
    "    weather_st2.loc[index, 'HeatWeek'] = weather_st2['Heat'][max(index-N_days, 0):index].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Heat' is not needed anymore\n",
    "weather_st1 = weather_st1.drop('Heat', axis=1)\n",
    "weather_st2 = weather_st2.drop('Heat', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature: total precipitation over last 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_st1['CumulativePrecip'] = 0\n",
    "weather_st2['CumulativePrecip'] = 0\n",
    "\n",
    "N_days = 14\n",
    "\n",
    "# The predictions only begin in June while the weather is from May, \n",
    "# so it doesn't matter that calculation is overlapping on the year boundaries\n",
    "\n",
    "for index, row in weather_st1.iterrows():\n",
    "    weather_st1.loc[index, 'CumulativePrecip'] = weather_st1['PrecipTotal'][max(index-N_days, 0):index].sum()\n",
    "\n",
    "for index, row in weather_st2.iterrows():\n",
    "    weather_st2.loc[index, 'CumulativePrecip'] = weather_st2['PrecipTotal'][max(index-N_days, 0):index].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature: average temperature over last 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_st1['TavgOverNDays'] = 0\n",
    "weather_st2['TavgOverNDays'] = 0\n",
    "\n",
    "N_days = 14\n",
    "\n",
    "# The predictions only begin in June while the weather is from May, \n",
    "# so it doesn't matter that calculation is overlapping on the year boundaries\n",
    "\n",
    "\n",
    "for index, row in weather_st1.iterrows():\n",
    "    weather_st1.loc[index, 'TavgOverNDays'] = weather_st1['Tavg'][max(index-N_days, 0):index].sum()/N_days\n",
    "\n",
    "for index, row in weather_st2.iterrows():\n",
    "    weather_st2.loc[index, 'TavgOverNDays'] = weather_st2['Tavg'][max(index-N_days, 0):index].sum()/N_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the data from 2 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = weather_st1.merge(weather_st2, on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set related features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature: amount of days that passed since 01/06 of the respective year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather['DayNumber'] = 0\n",
    "for index, row in weather.iterrows():\n",
    "    year = row['Date'].year\n",
    "    first_day_of_summer = pd.datetime(year, 6, 1)\n",
    "    weather.loc[index, 'DayNumber'] = (row['Date'] - first_day_of_summer).days\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append merged data to the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(weather, on='Date')\n",
    "test = test.merge(weather, on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average the weather parameters by distance to the station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate_params(data, attributes):\n",
    "    # This version uses vectorization and is a lot faster\n",
    "    # Chicago is small enough that we can treat coordinates as rectangular.\n",
    "    station = np.array([[41.995, -87.933],\n",
    "                         [41.786, -87.752]])\n",
    "    # The distances from each training example to the weather stations:\n",
    "    data['Dist1'] = (((1 - data[['Latitude', 'Longitude']] + station[0]))**2).sum(axis=1)**0.5\n",
    "    data['Dist2'] = (((1 - data[['Latitude', 'Longitude']] + station[1]))**2).sum(axis=1)**0.5\n",
    "    data['TotDist'] = data['Dist1'] + data['Dist2']\n",
    "         \n",
    "    # Take the weighted average of the attributes\n",
    "    for attr in attributes:\n",
    "        data[attr] = data[attr + '_x']*data['Dist1']/data['TotDist'] + data[attr + '_y']*data['Dist2']/data['TotDist']\n",
    "        # Data from 2 stations is no longer needed\n",
    "        data = data.drop([attr + '_x', attr + '_y'], axis=1)\n",
    "    \n",
    "    data = data.drop(['Dist1', 'Dist2', 'TotDist'], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['Tmax', 'Tmin', 'PrecipTotal', 'Tavg', 'CumulativeHeat', 'CumulativePrecip', 'TavgOverNDays', 'HeatWeek']\n",
    "train = interpolate_params(train, columns)\n",
    "test = interpolate_params(test, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature: number of rows for the same species on the same day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grouped = train.groupby(by=['Date'])\n",
    "count = (grouped.size() - grouped.size().min()) / (grouped.size().max() - grouped.size().min())\n",
    "count = pd.DataFrame(count).reset_index()\n",
    "count.columns = ['Date', 'NormalizedCount']\n",
    "train = train.merge(pd.DataFrame(count), on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = test.groupby(by=['Date'])\n",
    "count = (grouped.size() - grouped.size().min()) / (grouped.size().max() - grouped.size().min())\n",
    "count = pd.DataFrame(count).reset_index()\n",
    "count.columns = ['Date', 'NormalizedCount']\n",
    "count\n",
    "test = test.merge(pd.DataFrame(count), on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature: replace the species name by 1-of-N species vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_species = 6\n",
    "def species_vector(species):\n",
    "    species_map = {'CULEX RESTUANS' : \"100000\",\n",
    "                  'CULEX TERRITANS' : \"010000\",\n",
    "                  'CULEX PIPIENS'   : \"001000\",\n",
    "                  'CULEX PIPIENS/RESTUANS' : \"101000\",\n",
    "                  'CULEX ERRATICUS' : \"000100\",\n",
    "                  'CULEX SALINARIUS': \"000010\",\n",
    "                  'CULEX TARSALIS' :  \"000001\",\n",
    "                  'UNSPECIFIED CULEX': \"001100\"}\n",
    "    return pd.Series([b for b in species_map[species]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_species):\n",
    "    train['s' + str(i)] = 0\n",
    "    test['s' + str(i)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[['s0', 's1', 's2', 's3', 's4', 's5']] = train['Species'].apply(species_vector)\n",
    "test[['s0', 's1', 's2', 's3', 's4', 's5']] = test['Species'].apply(species_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop('Species', axis=1)\n",
    "test = test.drop('Species', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get rid of unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Tmax', 'Tmin', 'Tavg', 'CumulativeHeat', 'PrecipTotal', 's5'], axis=1) \n",
    "test = test.drop(['Tmax', 'Tmin', 'Tavg', 'CumulativeHeat', 'PrecipTotal', 's5'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>WnvPresent</th>\n",
       "      <th>DayNumber</th>\n",
       "      <th>CumulativePrecip</th>\n",
       "      <th>TavgOverNDays</th>\n",
       "      <th>HeatWeek</th>\n",
       "      <th>NormalizedCount</th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>1.541767</td>\n",
       "      <td>64.211675</td>\n",
       "      <td>-26.030463</td>\n",
       "      <td>0.03663</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Latitude  Longitude  WnvPresent  DayNumber  CumulativePrecip  \\\n",
       "0 2007-05-29  41.95469 -87.800991           0         -3          1.541767   \n",
       "\n",
       "   TavgOverNDays   HeatWeek  NormalizedCount s0 s1 s2 s3 s4  \n",
       "0      64.211675 -26.030463          0.03663  1  0  1  0  0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>DayNumber</th>\n",
       "      <th>CumulativePrecip</th>\n",
       "      <th>TavgOverNDays</th>\n",
       "      <th>HeatWeek</th>\n",
       "      <th>NormalizedCount</th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>10</td>\n",
       "      <td>3.793777</td>\n",
       "      <td>68.674002</td>\n",
       "      <td>11.969537</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Latitude  Longitude  DayNumber  CumulativePrecip  TavgOverNDays  \\\n",
       "0 2008-06-11  41.95469 -87.800991         10          3.793777      68.674002   \n",
       "\n",
       "    HeatWeek  NormalizedCount s0 s1 s2 s3 s4  \n",
       "0  11.969537                0  1  0  1  0  0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Checking model quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_jobs=-1, n_estimators=1000, min_samples_split=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(clf, train):\n",
    "    \"\"\"Leaves one year out and trains the classifier on the rest\n",
    "       then makes the prediction for the remaining year\"\"\"\n",
    "    years = [2007, 2009, 2011, 2013]\n",
    "    accuracies = []\n",
    "\n",
    "    for year in years:\n",
    "        # Split the training set\n",
    "        new_train = train[train['Date'].apply(lambda x: x.year) != year]\n",
    "        train_target = new_train['WnvPresent']\n",
    "        new_train = new_train.drop('WnvPresent', axis=1)\n",
    "        \n",
    "        test = train[train['Date'].apply(lambda x: x.year) == year]\n",
    "        test_target = test['WnvPresent']\n",
    "        test = test.drop('WnvPresent', axis=1)\n",
    "    \n",
    "        # Train the classifier\n",
    "        clf.fit(new_train.drop('Date', axis=1), train_target)\n",
    "        \n",
    "        # Make predictions for the left-out year\n",
    "        predictions = clf.predict_proba(test.drop('Date', axis=1))[:,1]\n",
    "        \n",
    "        # Calculate AUC\n",
    "        accuracies.append(metrics.roc_auc_score(test_target, predictions))\n",
    "        \n",
    "    return {'for_separate_years' : accuracies, 'average': float(sum(accuracies))/len(accuracies)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average': 0.6883504478992368,\n",
       " 'for_separate_years': [0.68141045395282684,\n",
       "  0.68286523483596884,\n",
       "  0.63436821899515938,\n",
       "  0.75475788381299225]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier(clf, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.05050752e-01,   1.19593085e-01,   5.14281597e-02,\n",
       "         8.83329556e-02,   1.76840189e-01,   1.32190100e-01,\n",
       "         1.61600066e-01,   1.12707725e-01,   2.87670191e-03,\n",
       "         4.82051050e-02,   0.00000000e+00,   1.17331392e-03,\n",
       "         1.84622331e-06])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=1,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop('Date', axis=1)\n",
    "test = test.drop('Date', axis=1)\n",
    "clf.fit(train.drop('WnvPresent', axis=1), train['WnvPresent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the predictions and write them to the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = 'temp_over_14_onehot.csv'\n",
    "predictions = clf.predict_proba(test)[:,1]\n",
    "sample['WnvPresent'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
